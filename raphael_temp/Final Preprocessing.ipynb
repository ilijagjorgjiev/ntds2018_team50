{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import csv \n",
    "\n",
    "#Location of the data_folder \n",
    "data_folder      =\"/nvme/drive_1/NTDS_Final/\"\n",
    "users            = pd.read_csv(data_folder+\"usersdata.csv\",delimiter='\\t',header=None).values\n",
    "filtered_users   = pd.read_csv(data_folder+\"filtered_users.csv\",delimiter=',').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I. Split Relations by Type **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_writers = []\n",
    "for feature in [1,2,3,4,5,6,7]: \n",
    "    csv_writers.append(csv.writer(open(data_folder+\"filtering/relations_type_\"+\\\n",
    "                                       str(feature)+\".csv\",\"wt\"),delimiter='\\t'))\n",
    "\n",
    "with open(data_folder+\"relations.csv\", \"rt\") as f_in:\n",
    "    reader             = csv.reader(f_in, delimiter=\"\\t\")\n",
    "    \n",
    "    for i, line in enumerate(reader):    \n",
    "        node_1             = line[2]  \n",
    "        node_2             = line[3]\n",
    "\n",
    "        csv_writers[int(line[4])-1].writerow(line)\n",
    "         \n",
    "        if i%1000 is 0:\n",
    "            print(\"\\r\"+str(i) +\" relations processed\", sep=' ', end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II. Track (user_id,index) Pairs **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx_dict          = {}\n",
    "filtered_user_idx_dict = {}\n",
    "\n",
    "for i,user in enumerate(users):\n",
    "    user_idx_dict[user[0]]=i\n",
    "\n",
    "for i,user in enumerate(filtered_users): \n",
    "    filtered_user_idx_dict[user[0]]=i #user_idx_dict[user[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** III. Create Adjacency Matrices **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "for feature in [1,2,3,4,5,6,7]:\n",
    "    with open(data_folder+\"filtering/relations_type_\"+\\\n",
    "              str(feature)+\".csv\") as f_in: \n",
    "        \n",
    "        adj     = sp.lil_matrix((filtered_users.shape[0], filtered_users.shape[0]), dtype='i2')    \n",
    "        reader  = csv.reader(f_in, delimiter=\"\\t\")\n",
    "        \n",
    "        for line in reader:    \n",
    "        \n",
    "            i+=1  \n",
    "            \n",
    "            if int(line[3]) in filtered_user_idx_dict and int(line[2]) in filtered_user_idx_dict:\n",
    "                adj[filtered_user_idx_dict[int(line[3])],filtered_user_idx_dict[int(line[2])]] = 1     \n",
    "                adj[filtered_user_idx_dict[int(line[2])],filtered_user_idx_dict[int(line[3])]] = 1\n",
    "        \n",
    "            if i%1000 is 0:\n",
    "                print(\"\\r\"+str(i) +\" relations processed\", sep=' ', end='', flush=True)\n",
    "        \n",
    "        csr = adj.tocsr()\n",
    "\n",
    "        sp.save_npz(data_folder+\"filtering/adjacency_\"+str(feature)+\".npz\",csr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntds_2018",
   "language": "python",
   "name": "ntds_2018"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
