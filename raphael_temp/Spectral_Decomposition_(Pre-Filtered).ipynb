{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import keras as ks \n",
    "import numpy as np\n",
    "import script_config as sc\n",
    "\n",
    "\n",
    "# Calculated for 2 Hop\n",
    "maximum_neighborhood_size = sc._config_maximum_neighborhood_size\n",
    "data_folder               = sc._config_data_folder\n",
    "random_seed               = sc._config_random_seed\n",
    "availible_threads         = sc._config_availible_threads\n",
    "feature_permutations      = sc._config_feature_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_undirected_adjacency(filename):\n",
    "    \n",
    "    loaded_data = np.load(filename)\n",
    "    users       = loaded_data['local_neighbors']\n",
    "    relations   = loaded_data['local_relations'] \n",
    "    adj         = np.zeros((len(users),len(users)))\n",
    "    \n",
    "    # Randomly Permute all nodes except the first one \n",
    "    users[1:] = np.random.permutation(users[1:])\n",
    "    \n",
    "    for relation in relations: \n",
    "        idx_1 = np.where(users[:,0] is relations[2]) \n",
    "        idx_2 = np.where(users[:,0] is relations[3])\n",
    "        adj[idx_1,idx_2] = 1\n",
    "        adj[idx_2,idx_1] = 1\n",
    "    \n",
    "    return (tf.convert_to_tensor(adj),tf.constant(users[0,0]))\n",
    "\n",
    "def create_spectral_decomposition(adjacency): \n",
    "    \n",
    "    n_nodes              = tf.shape(adjacency)[0]\n",
    "    \n",
    "    degrees_inv_sqrt     = tf.reshape(tf.math.pow(tf.math.sqrt(tf.math.reduce_sum(adjacency,axis=0)), \n",
    "                                                  tf.constant([-1]*n_nodes)),[n_nodes,1]) \n",
    "    \n",
    "    normalized_laplacian = tf.subtract(tf.eye(n_nodes),\n",
    "                                       tf.multiply(adjacency,\n",
    "                                                   tf.linalg.matmul(degrees_inv_sqrt, \n",
    "                                                                    tf.transpose(degrees_inv_sqrt)) ))\n",
    "\n",
    "    e_values, e_vectors   = tf.linalg.eigh(normalized_laplacian)\n",
    "    \n",
    "    features              = tf.multiply(e_values,e_vectors[0,:])\n",
    "    \n",
    "    return features \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /nvme/drive_1/NTDS_Final/spectral_decomp \n",
    "!rm -r /nvme/drive_1/NTDS_Final/spectral_decomp/filtered\n",
    "!mkdir /nvme/drive_1/NTDS_Final/spectral_decomp/filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=random_seed)\n",
    "\n",
    "# Start with tensor of files containing adjacency lists \n",
    "file_name_tensor = tf.data.Dataset.list_files(\"/nvme/drive_1/NTDS_Final/local_list/filtered/*.csv\",\n",
    "                                              shuffle=True,seed=random_seed)\n",
    "\n",
    "# Create adjacency matrices and interleave versions with permuted node indices  \n",
    "adjacency_tensor, ground_truth = file_name_tensor.interleave(lambda x:\n",
    "                                       tf.data.TextLineDataset(x)\n",
    "                                        .repeat(feature_permutations)\n",
    "                                           .map(create_undirected_adjacency, \n",
    "                                                num_parallel_calls=tf.constant(availible_threads)),\n",
    "                       cycle_length=tf.constant(feature_permutations), \n",
    "                       block_length=1, \n",
    "                       num_parallel_calls=tf.constant(availible_threads))\n",
    "\n",
    "#\n",
    "feature_tensor = adjacency_tensor.shuffle(tf.constant(100),seed=random_seed)\\\n",
    "                                 .map(create_spectral_decomposition,num_parallel_calls=tf.constant(availible_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ks.Sequential([\n",
    "            ks.layers.Dense(128, activation=tf.nn.relu),\n",
    "            ks.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntds_2018",
   "language": "python",
   "name": "ntds_2018"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
