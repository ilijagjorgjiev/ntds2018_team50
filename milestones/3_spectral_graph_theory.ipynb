{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'18] milestone 3: spectral graph theory\n",
    "[ntds'18]: https://github.com/mdeff/ntds_2018\n",
    "\n",
    "[Michaël Defferrard](http://deff.ch), [EPFL LTS2](https://lts2.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: 50\n",
    "* Students: Görkem Çamli, Raphael Laporte, Ilija Gjorgjiev, Murat Genc\n",
    "* Dataset: Spammers on Social Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to two sentences.\n",
    "* Code has to be clean.\n",
    "* You cannot import any other library than we imported.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The goal of this milestone is to get familiar with the graph Laplacian and its spectral decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Load your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a `No module named 'sklearn'` error when running the below cell, install [scikit-learn](https://scikit-learn.org) with `conda install scikit-learn` (after activating the `ntds_2018` environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's denote your graph as $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E}, A)$, where $\\mathcal{V}$ is the set of nodes, $\\mathcal{E}$ is the set of edges, $A \\in \\mathbb{R}^{N \\times N}$ is the (weighted) adjacency matrix, and $N = |\\mathcal{V}|$ is the number of nodes.\n",
    "\n",
    "Import the adjacency matrix $A$ that you constructed in the first milestone.\n",
    "(You're allowed to update it between milestones if you want to.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = sp.load(\"undirected_adjacency.npy\")\n",
    "adjacency = sparse.csr_matrix(adjacency,adjacency.shape,dtype=np.float16)\n",
    "n_nodes =  adjacency.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Graph Laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "From the (weighted) adjacency matrix $A$, compute both the combinatorial (also called unnormalized) and the normalized graph Laplacian matrices.\n",
    "\n",
    "Note: if your graph is weighted, use the weighted adjacency matrix. If not, use the binary adjacency matrix.\n",
    "\n",
    "For efficient storage and computation, store these sparse matrices in a [compressed sparse row (CSR) format](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_.28CSR.2C_CRS_or_Yale_format.29)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_laplacian_normalized(L, degrees):\n",
    "    newD =  sparse.spdiags(1/np.sqrt(degrees),[0],degrees.size,degrees.size)\n",
    "    return ((newD @ L) @ newD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = adjacency.sum(0)\n",
    "degree_matrix = sparse.spdiags(degrees,[0],n_nodes,n_nodes)\n",
    "degree_matrix = sparse.csr_matrix(degree_matrix,degree_matrix.shape,dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t36.0\n",
      "  (0, 132)\t-1.0\n",
      "  (0, 4091)\t-1.0\n",
      "  (0, 6059)\t-1.0\n",
      "  (0, 6752)\t-1.0\n",
      "  (0, 7957)\t-1.0\n",
      "  (0, 8632)\t-1.0\n",
      "  (0, 8984)\t-1.0\n",
      "  (0, 11369)\t-1.0\n",
      "  (0, 11514)\t-1.0\n",
      "  (0, 11972)\t-1.0\n",
      "  (0, 12807)\t-1.0\n",
      "  (0, 13748)\t-1.0\n",
      "  (0, 17727)\t-1.0\n",
      "  (0, 20733)\t-1.0\n",
      "  (0, 22391)\t-1.0\n",
      "  (0, 25958)\t-1.0\n",
      "  (0, 26287)\t-1.0\n",
      "  (0, 27137)\t-1.0\n",
      "  (0, 28955)\t-1.0\n",
      "  (0, 31532)\t-1.0\n",
      "  (0, 35227)\t-1.0\n",
      "  (0, 35605)\t-1.0\n",
      "  (0, 44200)\t-1.0\n",
      "  (0, 46748)\t-1.0\n",
      "  :\t:\n",
      "  (62160, 62160)\t1.0\n",
      "  (62161, 11369)\t-1.0\n",
      "  (62161, 62161)\t1.0\n",
      "  (62162, 11369)\t-1.0\n",
      "  (62162, 62162)\t1.0\n",
      "  (62163, 35605)\t-1.0\n",
      "  (62163, 62163)\t1.0\n",
      "  (62164, 46877)\t-1.0\n",
      "  (62164, 62164)\t1.0\n",
      "  (62165, 27137)\t-1.0\n",
      "  (62165, 62165)\t1.0\n",
      "  (62166, 35605)\t-1.0\n",
      "  (62166, 62166)\t1.0\n",
      "  (62167, 52866)\t-1.0\n",
      "  (62167, 62167)\t1.0\n",
      "  (62168, 17727)\t-1.0\n",
      "  (62168, 62168)\t1.0\n",
      "  (62169, 35605)\t-1.0\n",
      "  (62169, 62169)\t1.0\n",
      "  (62170, 55047)\t-1.0\n",
      "  (62170, 62170)\t1.0\n",
      "  (62171, 11972)\t-1.0\n",
      "  (62171, 62171)\t1.0\n",
      "  (62172, 11972)\t-1.0\n",
      "  (62172, 62172)\t1.0\n"
     ]
    }
   ],
   "source": [
    "#Laplacian Combinatorial\n",
    "laplacian_combinatorial  =  degree_matrix - adjacency\n",
    "print (laplacian_combinatorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 132)\t-0.019779697\n",
      "  (0, 4091)\t-0.0036155079\n",
      "  (0, 6059)\t-0.0024152054\n",
      "  (0, 6752)\t-0.0028115632\n",
      "  (0, 7957)\t-0.0025029427\n",
      "  (0, 8632)\t-0.0026455028\n",
      "  (0, 8984)\t-0.020515248\n",
      "  (0, 11369)\t-0.0026448364\n",
      "  (0, 11514)\t-0.016343012\n",
      "  (0, 11972)\t-0.0037800767\n",
      "  (0, 12807)\t-0.0049062064\n",
      "  (0, 13748)\t-0.011904763\n",
      "  (0, 17727)\t-0.0037408348\n",
      "  (0, 20733)\t-0.015027828\n",
      "  (0, 22391)\t-0.019920478\n",
      "  (0, 25958)\t-0.004561505\n",
      "  (0, 26287)\t-0.021166688\n",
      "  (0, 27137)\t-0.0022245965\n",
      "  (0, 28955)\t-0.0041485564\n",
      "  (0, 31532)\t-0.0031440945\n",
      "  (0, 35227)\t-0.008343769\n",
      "  (0, 35605)\t-0.0021668791\n",
      "  (0, 44200)\t-0.0035811253\n",
      "  (0, 46748)\t-0.017190354\n",
      "  :\t:\n",
      "  (62160, 62160)\t1.0\n",
      "  (62161, 11369)\t-0.015869018\n",
      "  (62161, 62161)\t1.0\n",
      "  (62162, 11369)\t-0.015869018\n",
      "  (62162, 62162)\t1.0\n",
      "  (62163, 35605)\t-0.013001274\n",
      "  (62163, 62163)\t1.0\n",
      "  (62164, 46877)\t-0.023596458\n",
      "  (62164, 62164)\t1.0\n",
      "  (62165, 27137)\t-0.013347578\n",
      "  (62165, 62165)\t1.0\n",
      "  (62166, 35605)\t-0.013001274\n",
      "  (62166, 62166)\t1.0\n",
      "  (62167, 52866)\t-0.012659242\n",
      "  (62167, 62167)\t1.0\n",
      "  (62168, 17727)\t-0.022445008\n",
      "  (62168, 62168)\t1.0\n",
      "  (62169, 35605)\t-0.013001274\n",
      "  (62169, 62169)\t1.0\n",
      "  (62170, 55047)\t-0.01981461\n",
      "  (62170, 62170)\t1.0\n",
      "  (62171, 11972)\t-0.02268046\n",
      "  (62171, 62171)\t1.0\n",
      "  (62172, 11972)\t-0.02268046\n",
      "  (62172, 62172)\t1.0\n"
     ]
    }
   ],
   "source": [
    "#Laplacian Normalized\n",
    "laplacian_normalized = compute_laplacian_normalized(laplacian_combinatorial, degrees)\n",
    "print(laplacian_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one of them as the graph Laplacian $L$ for the rest of the milestone.\n",
    "We however encourage you to run the code with both to get a sense of the difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Compute the eigendecomposition of the Laplacian $L = U \\Lambda U^\\top$, where the columns $u_k \\in \\mathbb{R}^N$ of $U = [u_1, \\dots, u_N] \\in \\mathbb{R}^{N \\times N}$ are the eigenvectors and the diagonal elements $\\lambda_k = \\Lambda_{kk}$ are the corresponding eigenvalues.\n",
    "\n",
    "Make sure that the eigenvalues are ordered, i.e., $0 = \\lambda_1 \\leq \\lambda_2 \\leq \\dots \\leq \\lambda_N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_c, v_c = sparse.linalg.eigsh(laplacian_combinatorial,k=1000,which='LM',tol=0.001)\n",
    "np.save(\"eigenvectors_combinatorial\",v_c)\n",
    "np.save(\"eigenvalues_combinatorial\",w_c)\n",
    "w_n, v_n = sparse.linalg.eigsh(laplacian_normalized,k=1000,which='LM',tol=0.001)\n",
    "np.save(\"eigenvectors_normalized\",v_n)\n",
    "np.save(\"eigenvalues_normalized\" ,w_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justify your choice of eigensolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "As mentioned above in the comment, we decided to compute only 200 eigenvalues and eigenvectors as our matrix is too big, and it makes the kernel crash always. Thus we would have originaly used the function mentioned in the above comments scipy.linalg.eigh(laplacian.toarray()), as it would have returned us the eigenvalues in asceding order and all of them, also our matrix is real symmetric(hermitian). Otherwise we decided to go with eigsh as it allows us to specify how many eigenvalues and eigenvectors we want and in what order(in our case we would need to use which=\"SM\", but as we said the matrix is too big and running make take hours of running even for 200, that is why we decided to go with computing just 200 eigenvalues and eigenvectors any of them actually), as this would make our cell actually execute, even though still it takes some time. The eigsh can be executed also since our matrix is hermitian and sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "We can write $L = S S^\\top$. What is the matrix $S$? What does $S^\\top x$, with $x \\in \\mathbb{R}^N$, compute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "Matrix $S$ is the incidence matrix. It has a shape of ($|E|$, $|V|$) , where $|E|$ is the number of edges starting from edge 1 to N and $|V|$ is the number of vertices in the graph. The incidence matrix consits of values of $0$, $1$, $-1$. In the incidence matrix each entry shows the direction of the edge written in the following way:\n",
    "\n",
    "For example if $E_0(i,j)$, exists with $i = 0$ and $j = 1$ then in the $S[0][i] = 1$ and $S[0][j] = -1$. Showing the direction of Edge 0. All the other entries are $0s$ otherwise. When multiplying $S$ with $S^\\top$, what actually happens is each such $E_{row}$ let's call it $E_k$ will contain $1$ and $-1$, all other entries would be $0s$.\n",
    "\n",
    "In this case we basically have product of 2 vectors of size 2, since the $0s$ do make any change in the product, even though they are actually there as making the order of positions fine. In this case, what we are going to get a matrix of size $4x4$(not considering the $0s$) in which the diagonals entries count the incident edges(degree of each vertex $i$ in the end) and the off-diagonals will be always multiply a $1$ with $-1$(basically the adjacency matrix), which says that the edge is adjacent and thus we effectively lose the direction. Thus, we can conclude that the laplacian does not depend on the edge direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Show that $\\lambda_k = \\| S^\\top u_k \\|_2^2$, where $\\| \\cdot \\|_2^2$ denotes the squared Euclidean norm (a.k.a. squared $L^2$ norm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the quantity $\\| S^\\top x \\|_2^2$ tell us about $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What is the value of $u_0$, both for the combinatorial and normalized Laplacians?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your annswer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Look at the spectrum of the Laplacian by plotting the eigenvalues.\n",
    "Comment on what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many connected components are there in your graph? Answer using the eigenvalues only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there an upper bound on the eigenvalues, i.e., what is the largest possible eigenvalue? Answer for both the combinatorial and normalized Laplacians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Laplacian eigenmaps\n",
    "\n",
    "*Laplacian eigenmaps* is a method to embed a graph $\\mathcal{G}$ in a $d$-dimensional Euclidean space.\n",
    "That is, it associates a vector $z_i \\in \\mathbb{R}^d$ to every node $v_i \\in \\mathcal{V}$.\n",
    "The graph $\\mathcal{G}$ is thus embedded as $Z \\in \\mathbb{R}^{N \\times d}$.\n",
    "\n",
    "From now on, if your graph has more than one connected component, work with the giant component only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What do we use Laplacian eigenmaps for? (Or more generally, graph embeddings.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Embed your graph in $d=2$ dimensions with Laplacian eigenmaps.\n",
    "Try with and without re-normalizing the eigenvectors by the degrees, then keep the one your prefer.\n",
    "\n",
    "**Recompute** the eigenvectors you need with a partial eigendecomposition method for sparse matrices.\n",
    "When $k \\ll N$ eigenvectors are needed, partial eigendecompositions are much more efficient than complete eigendecompositions.\n",
    "A partial eigendecomposition scales as $\\Omega(k |\\mathcal{E}|$), while a complete eigendecomposition costs $\\mathcal{O}(N^3)$ operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the nodes embedded in 2D. Comment on what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the embedding $Z \\in \\mathbb{R}^{N \\times d}$ preserve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Spectral clustering\n",
    "\n",
    "*Spectral clustering* is a method to partition a graph into distinct clusters.\n",
    "The method associates a feature vector $z_i \\in \\mathbb{R}^d$ to every node $v_i \\in \\mathcal{V}$, then runs [$k$-means](https://en.wikipedia.org/wiki/K-means_clustering) in the embedding space $\\mathbb{R}^d$ to assign each node $v_i \\in \\mathcal{V}$ to a cluster $c_j \\in \\mathcal{C}$, where $k = |\\mathcal{C}|$ is the number of desired clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Choose $k$ and $d$. How did you get to those numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "1. Embed your graph in $\\mathbb{R}^d$ as $Z \\in \\mathbb{R}^{N \\times d}$.\n",
    "   Try with and without re-normalizing the eigenvectors by the degrees, then keep the one your prefer.\n",
    "1. If you want $k=2$ clusters, partition with the Fiedler vector. For $k > 2$ clusters, run $k$-means on $Z$. Don't implement $k$-means, use the `KMeans` class imported from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "v_normalized = preprocessing.normalize(X, norm='l2')\n",
    "print v_normalized\n",
    "\n",
    "#k: number of clusters\n",
    "k=3\n",
    "\n",
    "#visualize laplacian spectrum with eigenvector v\n",
    "kmeans = KMeans(k)\n",
    "kmeans.fit(v)\n",
    "y_kmeans = kmeans.predict(v)\n",
    "#color the graph\n",
    "\n",
    "plt.register_cmap(name='viridis', cmap=cmaps.viridis)\n",
    "plt.set_cmap(cmaps.viridis)\n",
    "plt.scatter(v, c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "#visualize laplacian spectrum with normalized eigenvector v_normalized\n",
    "kmeans = KMeans(k)\n",
    "kmeans.fit(v_normalized)\n",
    "y_kmeans = kmeans.predict(v_normalized)\n",
    "\n",
    "#color the graph\n",
    "plt.scatter(v_normalized, c=y_kmeans, s=50, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Use the computed cluster assignment to reorder the adjacency matrix $A$.\n",
    "What do you expect? What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "If you have ground truth clusters for your dataset, compare the cluster assignment from spectral clustering to the ground truth.\n",
    "A simple quantitative measure is to compute the percentage of nodes that have been correctly categorized.\n",
    "If you don't have a ground truth, qualitatively assess the quality of the clustering.\n",
    "\n",
    "Ground truth clusters are the \"real clusters\".\n",
    "For example, the genre of musical tracks in FMA, the category of Wikipedia articles, the spammer status of individuals, etc.\n",
    "Look for the `labels` in the [dataset descriptions](https://github.com/mdeff/ntds_2018/tree/master/projects/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "Plot the cluster assignment (one color per cluster) on the 2D embedding you computed above with Laplacian eigenmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "\n",
    "Why did we use the eigenvectors of the graph Laplacian as features? Could we use other features for clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntds_2018",
   "language": "python",
   "name": "ntds_2018"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
